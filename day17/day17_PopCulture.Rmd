---
title: "Untitled"
author: "Sung Inkyung"
date: '2021 6 15'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidytext)
```


```{r}
avatar <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-08-11/avatar.csv")


avatar %>% 
  count(character, sort = T)
```


```{r}

avatar %>% 
  filter(!is.na(character_words)) %>% 
  mutate(book = fct_inorder(book),
         character = fct_lump(character, 10)) %>% 
  count(book, character) %>% 
  mutate(character = reorder_within(character, n, book)) %>% 
  ggplot(aes(n, character, fill = book)) +
  geom_col(show.legend = F) +
  facet_wrap(~book, scales = "free") +
  scale_y_reordered() +
  scale_fill_manual(values = c( "#7094b7",
                               "#5c3026",
                               "#e25822"
  )) +
  labs(y = NULL)
```


```{r}
avatar <- avatar %>% 
  filter(!is.na(character_words)) %>% 
  mutate(aang = if_else(character == "Aang", "Aang", "Other")) %>% 
  select(aang, book, text = character_words)

library(tidylo)
library(tvthemes)

avatar_log <- avatar %>% 
  unnest_tokens(word, text) %>% 
  count(aang, word) %>% 
  bind_log_odds(aang, word, n) %>% 
  arrange(-log_odds_weighted)

avatar_log %>% 
  group_by(aang) %>% 
  top_n(15) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, log_odds_weighted)) %>% 
  ggplot(aes(log_odds_weighted, word, fill = aang)) +
  geom_col(alpha = .8, show.legend = F) +
  facet_wrap(~aang, scales = "free") +
  scale_fill_avatar(palette = "AirNomads") +
  labs(y = "")
```
```{r}
library(textfeatures)

tf <- textfeatures::textfeatures(avatar,
                                 sentiment = F, 
                                 word_dims = 0,
                                 normalize = F,
                                 verbose = F)

tf %>% 
  bind_cols(avatar) %>% 
  group_by(aang) %>% 
  summarize(across(starts_with("n_"), mean)) %>% 
  pivot_longer(starts_with("n_"),
               names_to = "text_feature") %>% 
  filter(value > .01) %>% 
  mutate(text_feature = fct_reorder(text_feature, -value)) %>% 
  ggplot(aes(aang, value, fill = aang)) +
  geom_col(position = "dodge",
           alpha = .8,
           show.legend = F) +
  facet_wrap(~text_feature, scales = "free",
             ncol = 6) +
  scale_fill_avatar("AirNomads") +
  labs(x = "",
       y = "Mean text features per spoken line")
```


```{r}
library(tidymodels)

set.seed(123)

avatar_split <- initial_split(avatar, strata = aang)
avatar_train <- training(avatar_split)
avatar_text <- testing(avatar_split)

set.seed(123)

avatar_folds <- vfold_cv(avatar_train, strata = aang)


## prepocess
library(textrecipes)
library(themis)


avatar_rec <- recipe(aang ~text, data = avatar_train) %>% 
  step_downsample(aang) %>% 
  step_textfeature(text) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())

avatar_prep <- prep(avatar_rec)

juice(avatar_prep)
```


```{r}
rf_spec <- rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

svm_spec <- svm_rbf(cost = .5) %>% 
  set_engine("kernlab") %>% 
  set_mode("classification")

avatar_wf <- workflow() %>% 
  add_recipe(avatar_rec)

doParallel::registerDoParallel()

set.seed(123)

rf_rs <- avatar_wf %>% 
  add_model(rf_spec) %>% 
  fit_resamples(resamples = avatar_folds,
                metrics = metric_set(roc_auc, accuracy, sens, spec),
                control = control_grid(save_pred = T))
                        
```


```{r}
set.seed(123)

svm_rs <- avatar_wf %>% 
  add_model(svm_spec) %>% 
  fit_resamples(resamples = avatar_folds,
                metrics = metric_set(roc_auc, accuracy, sens, spec),
                control = control_grid(save_pred = T))


##Evaluate model

collect_metrics(rf_rs)

conf_mat_resampled(rf_rs)

collect_metrics(svm_rs)

conf_mat_resampled(svm_rs)


svm_rs %>% 
  collect_predictions() %>% 
  group_by(id) %>% 
  roc_curve(aang, .pred_Aang) %>% 
  ggplot(aes(1-specificity, sensitivity, 
             color = id)) +
  geom_abline(lty = 2, 
              color = "firebrick",
              size = 1.5) +
  geom_path(show.legend = F, 
            alpha = .6, 
            size = 1.2) +
  scale_color_avatar(palette = "EarthKingdom") +
  coord_equal()

```
```{r}
library(vip)

set.seed(123)

avatar_imp <- avatar_wf %>% 
  add_model(svm_spec) %>% 
  fit(avatar_train) %>% 
  pull_workflow_fit() %>% 
  vi(method = "permute",
     nsim = 10,
     target = "aang",
     metric = "auc",
     reference_class = "Other",
     pred_wrapper = kernlab::predict,
     train = juice(avatar_prep))

avatar_imp %>% 
  slice_max(Importance, n = 8) %>% 
  mutate(Variable = str_remove(Variable, "textfeature_text_n"),
         Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(Importance, Variable, color = Variable)) +
  geom_errorbar(aes(xmin = Importance - StDev,
                    xmax = Importance + StDev),
                alpha = .5, size = 1.3) +
  geom_point(size = 3) +
  scale_color_avatar(palette = "FireNation") +
  labs(y = "") +
  theme_light() +
  theme(legend.position =  "none")
```
```{r}
avatar_final <- avatar_wf %>% 
  add_model(svm_spec) %>% 
  last_fit(avatar_split)

avatar_final %>% 
  collect_metrics()

avatar_final %>% 
  collect_predictions() %>% 
  conf_mat(aang, .pred_class)


```

```{r}
netflix_titles <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv")

netflix_titles %>% 
  slice_sample(n = 10) %>% 
  pull(description)

netflix_titles %>% 
  count(type, sort = T)

netflix_titles %>% 
  unnest_tokens(word, description) %>% 
  anti_join(get_stopwords()) %>% 
  count(type, word, sort = T) %>% 
  group_by(type) %>% 
  slice_max(n, n = 15) %>% 
  ungroup() %>% 
  mutate(word = reorder_within(word, n, type)) %>% 
  ggplot(aes(n, word, fill = type)) +
  geom_col(show.legend = F,
           alpha = .8) +
  scale_y_reordered() +
  facet_wrap(~type, scales = "free") +
  labs(x = "Word Frequency",
      y = "",
      title = "Top Words in Netflix Description by Frequency") +
  theme_light()
 
```


```{r}
## Build a model

set.seed(123)

netflix_split <- netflix_titles %>% 
  select(type, description) %>% 
  initial_split(strata = type)

netflix_train <- training(netflix_split)
netflix_test <- testing(netflix_split)

set.seed(123)

netflix_folds <- vfold_cv(netflix_train, strata = type)

netflix_rec <- recipe(type ~ description, 
                      data = netflix_train) %>% 
  step_tokenize(description) %>% 
  step_tokenfilter(description, max_tokens = 1e3) %>% 
  step_tfidf(description) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_smote(type)


devtools::install_github("tidymodels/parsnip")

svm_spec <- svm_linear() %>%
  set_mode("classification") %>%
  set_engine("LiblineaR")


netflix_wf <- workflow() %>%
  add_recipe(netflix_rec) %>%
  add_model(svm_spec)
```


```{r}
doParallel::registerDoParallel()
set.seed(123)
svm_rs <- fit_resamples(
  netflix_wf,
  netflix_folds,
  metrics = metric_set(accuracy, recall, precision),
  control = control_resamples(save_pred = TRUE)
)

collect_metrics(svm_rs)

svm_rs %>%
  conf_mat_resampled(tidy = FALSE) %>%
  autoplot()


```


```{r}
## Fit and evaluate final model

final_fitted <- last_fit(
  netflix_wf,
  netflix_split,
  metrics = metric_set(accuracy, recall, precision)
)
collect_metrics(final_fitted)

collect_predictions(final_fitted) %>%
  conf_mat(type, .pred_class)


netflix_fit <- pull_workflow_fit(final_fitted$.workflow[[1]])

tidy(netflix_fit) %>%
```


```{r}
tidy(netflix_fit) %>%
  filter(term != "Bias") %>%
  group_by(sign = estimate > 0) %>%
  slice_max(abs(estimate), n = 15) %>%
  ungroup() %>%
  mutate(
    term = str_remove(term, "tfidf_description_"),
    sign = if_else(sign, "More from TV shows", "More from movies")
  ) %>%
  ggplot(aes(abs(estimate), fct_reorder(term, abs(estimate)), fill = sign)) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~sign, scales = "free") +
  labs(
    x = "Coefficient from linear SVM", y = NULL,
    title = "Which words are most predictive of movies vs. TV shows?",
    subtitle = "For description text of movies and TV shows on Netflix"
  )
```


```{r}
user_reviews <- readr::read_tsv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/user_reviews.tsv")



```


```{r}
user_reviews %>% 
  count(grade) %>% 
  ggplot(aes(grade, n)) +
  geom_col(fill = "midnightblue",
           alpha = .8)

user_reviews %>% 
  filter(grade > 8) %>% 
  sample_n(5) %>% 
  pull(text)

reviews_parsed <- user_reviews %>% 
  mutate(text = str_remove(text, "Expand$")) %>% 
  mutate(rating = case_when(grade > 7 ~ "good",
                            TRUE ~ "bad"))

words_per_review <- reviews_parsed %>% 
  unnest_tokens(word, text) %>% 
  count(user_name, name = "total_words")
  
  
words_per_review %>% 
  ggplot(aes(total_words)) +
  geom_histogram(fill = "midnightblue",
                 alpha = .8)
```


```{r}

## Build a model

set.seed(123)
review_split <- initial_split(reviews_parsed, strata = rating)
review_train <- training(review_split)
review_test <- testing(review_split)

review_rec <- recipe(rating ~ text, data = review_train) %>% 
  step_tokenize(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 500) %>% 
  step_tfidf(text) %>% 
  step_normalize(all_predictors())

review_prep <- prep(review_rec)
```


```{r}
lasso_spec <- logistic_reg(penalty = tune(),
                           mixture = 1) %>% 
  set_engine("glmnet")

lasso_wf <- workflow() %>% 
  add_recipe(review_rec) %>% 
  add_model(lasso_spec)
```


```{r}
## Tune model parameters

lambda_grid <- grid_regular(penalty(),
                            levels = 40)

set.seed(123)

review_folds <- bootstraps(review_train, strata = rating)
```


```{r}
doParallel::registerDoParallel()

set.seed(123)

lasso_grid <- tune_grid(lasso_wf,
                        resamples = review_folds,
                        grid = lambda_grid,
                        metrics = metric_set(roc_auc, ppv, npv))

lasso_grid %>% 
  collect_metrics()

lasso_grid %>% 
  collect_metrics() %>% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 1.5, 
            show.legend = F) +
  facet_wrap(~.metric) +
  scale_x_log10() +
  theme_light()
```


```{r}
## Choose the final model

best_auc <- lasso_grid %>% 
  select_best("roc_auc")

final_lasso <- finalize_workflow(lasso_wf, best_auc)

final_lasso %>% 
  fit(review_train) %>% 
  pull_workflow_fit() %>% 
  vi(lambda = best_auc$penalty) %>% 
  group_by(Sign) %>% 
  top_n(20, wt = abs(Importance)) %>% 
  ungroup() %>% 
  mutate(Importance = abs(Importance),
         Variable = str_remove(Variable, "tfidf_text_"),
         Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(Importance, Variable, fill = Sign)) +
  geom_col(show.legend = F) +
  facet_wrap(~ Sign, scales = "free_y") +
  labs(y = "")
```


```{r}
review_final <- last_fit(final_lasso, review_split)

review_final %>% 
  collect_metrics()

review_final %>% 
  collect_predictions() %>%  
  conf_mat(rating, .pred_class)
```


```{r}

```

